{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import math\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import keras\n",
    "\n",
    "from normalize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    # Load Data\n",
    "    # We load data into RAM since data is small and will fit in memory.\n",
    "    cells = pd.read_csv(\"tumor_cycif.csv\")\n",
    "    \n",
    "    # Keeps only the 'interesting' columns.\n",
    "    cells = cells.filter(regex=\"Cell Masks$\", axis=1).filter(regex=\"^(?!(Goat|DAPI))\", axis=1)\n",
    "    cells = np.array(cells)\n",
    "    \n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = get_data()\n",
    "\n",
    "# Number of cells\n",
    "assert cells.shape[0] == 12142\n",
    "# Number of features per input\n",
    "assert cells.shape[1] == 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two options for normalization:\n",
    "# 1- use the following;\n",
    "# 2- use StandardScaler append to the estimators. \n",
    "#\n",
    "# My experiments show that option one results to \n",
    "# a much lower MAE (~6k vs ~0.05). \n",
    "cells = normalize(cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate one of the markers as target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_split(cells, idx):\n",
    "    y = cells[:, idx]\n",
    "    # This reshape can simplify broadcasting.\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    \n",
    "    # `1` means delete column, while `0` means delete row.\n",
    "    X = np.delete(cells, idx, 1)\n",
    "    return X, y\n",
    "\n",
    "# The index of the marker column \n",
    "# whose values will be predicted \n",
    "# using other markers.\n",
    "idx = 10\n",
    "\n",
    "X, y = xy_split(cells, idx)\n",
    "\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    inputs = keras.Input(shape=(input_dim))\n",
    "    h1 = layers.Dense(input_dim, activation=\"relu\", kernel_initializer=\"normal\")(inputs)\n",
    "    outputs = layers.Dense(1, kernel_initializer=\"normal\")(h1)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.0005), loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE's: [-0.05093031 -0.05326689 -0.05720467 -0.05901065 -0.05213646 -0.0439412\n",
      " -0.04740405 -0.0635313  -0.05410788 -0.0566939 ]\n",
      "Baseline: -0.053822731226682664 (0.00539718588372297) MSE\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "#estimators.append(('standardize', StandardScaler()))\n",
    "# mlp: Multilayer Perceptron\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "#history = pipeline.fit(X, y)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "\n",
    "print(f\"MSE's: {results}\")\n",
    "print(f\"Baseline: {results.mean()} ({results.std()}) MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True)\n",
    "regressor = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "history = regressor.fit(X_train, y_train, epochs=50, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40182736]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual value: -0.6244806786550537\n",
      "Predicted value: -0.6300616264343262\n"
     ]
    }
   ],
   "source": [
    "idx_validation_cell = 22\n",
    "validation_cell = X_val[idx_validation_cell,:].reshape(1, X_val.shape[1])\n",
    "prediction = regressor.predict(validation_cell)\n",
    "print(f\"   Actual value: {y_val[idx_validation_cell][0]}\")\n",
    "print(f\"Predicted value: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
